---
title: "02: Interactive Data Viz"
subtitle: "Tables"
output: 
  html_document:
    highlight: pygment
---

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'))
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      class.source = "numberLines lineAnchors",
                      warning = FALSE, message = FALSE,
                      eval = TRUE)
```

In the last [section](03_maps.html) we learned how to make interactive maps. In this section we we will learn how to build interactive tables displaying information about our FIP code.

The `DT` package provides an R interface to the JavaScript library DataTables. R data objects (matrices or data frames) can be displayed as tables on HTML pages, and DataTables provides filtering, pagination, sorting, and many other features in the tables. Documentation and examples for DT can be found [here](https://rstudio.github.io/DT/)

The objective of this section is to build a function called `make_table` that takes a FIP code and builds a nice summary table of information. We are going to look at two options. The first, will return a table of all counties in the same state as the selected FIP code. The second is a bit more complicated (and optional!) but will scrape Wikipedia to get information about the county. Lets take a look at these options!

First though, load your required data as done in the other sections:

```{r, eval = TRUE}
## Load our helper file with our functions
source('./helpers.R')
counties = readRDS("./data/counties.rds")
covid19  = read_covid19()
today    = today_centroids(counties, covid19)
```

## Option 1: Sorting a table by state & counts:

Here we are going to take a FIP code, filter our data, extract the state, and then sort the counties in that state from largest COVID counts to smallest. 

After that we will only keep the needed columns and calculate a `DeathRate` as a measure of state effectiveness.

```{r}
# Fitler today's data to the LA County
myfip  = filter(today, fips == 6037)

# Filter todays data to the state of myfip
mydata = filter(today, state == myfip$state) %>% 
# Arrange the cases from largest to smallest
  arrange(desc(cases)) %>% 
# Drop the geometry column
  st_drop_geometry() %>% 
# Keep only the County name, cases and deaths
  select(County = county, Cases = cases, Deaths = deaths) %>% 
# Create a new variable called Death Rate and save it as a string for printing
  mutate(DeathRate = paste0(100* round(Deaths/Cases,2), "%"))


# Make an interactive Table!
datatable(mydata, 
          # add a title to the table
          caption = paste('COVID-19 Statistics', myfip$state, myfip$date)) 
```

## Option 2: Scraping Wikipedia Data

This second option is really cool. Here we are going to use the `name` variable we created to scrape the Wikipedia infobox for information!

```{r}
# Filter the input data to the input FIP code
myfip = filter(today, fips == 6037)
# Build a Wikipedia URL using the data attribute 'name'
url = paste0('https://en.wikipedia.org/wiki/',  gsub(" ", "_", myfip$name))
  # Steps:
  ## 1. Read the HTML from the URL
  ## 2. Read the Nodes from the HTML page and select the table with a class infobox
  ## 3. Convert raw HTML node to a data.frame
links <- read_html(url) %>%
           html_nodes("table.infobox") %>% 
           html_table(fill= TRUE) 
# Keep only the first element of the list (we dont care about the HTML stuff)
data = links[[1]]

## Make a datatable from the resulting data.frame and turn off paging
datatable(data,  
          caption = paste('Wikipedia Information:', myfip$name), 
          colnames = rep("", ncol(data)))
```

Super cool! You now know how to scrape information from Wikipedia information boxes for any topics! Lets add one of these to the `helper.R` file:


```{r}

make_table = function(today, FIPS){
  myfip = filter(today, fips == FIP)

  url = paste0('https://en.wikipedia.org/wiki/',  gsub(" ", "_", myfip$name)) %>% 
           read_html() %>%
           html_nodes("table.infobox") %>% 
           html_table(fill= TRUE) 

  l = url[[1]]
  # remove rows where the columns are identical
  ll = l[!l[,1] == l[,2],]

## Make a datatable from the resulting data.frame and turn off paging
  datatable(ll,  
          caption = paste('Wikipedia Information:', myfip$name),
          # Turn off some of the interactive components for this table.
          options = list(paging = FALSE, searching = FALSE, ordering = FALSE),
          colnames = rep("", ncol(ll)))
}

```

A complete `helpers.R` file can be found [here](https://github.com/mikejohnson51/COVID-19-dashboard/blob/master/helpers.R) for download / copy-paste. Just make sure if you chose to use it, that it goes in the right spot in you project, and that you modify a least a few of the aesthetic options in the graph table and maps.

Notice that all the visualization functions we have built rely on our `county`, `timeseries`, or `today` data and a user defined `FIP code`. From these we can make informative plots, maps and tables. 

## Conclusion

Congratulations! You finished the first section of this lab! We are now moving on to making our Shiny web applications.
The purpose of our Shiny Application will be to display the map, graph, and table resources on a common page, and allow user input (from sources like clicks and text-input) to change the FIP code and the resulting visualizations. To do this we need a special type of programming known as 'reactive'. Let move on the the next [section](05_shiny_basics.html) to build out the basics of our first Shiny App!

